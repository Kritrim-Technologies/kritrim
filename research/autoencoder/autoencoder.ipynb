{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pretty_midi\nimport sys\nsys.path.insert(0,'../input/folkmusic')\nimport midi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=midi.midi_datasets_to_samples(['../input/folkmusic/dataset'],48)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sample.shape)\n16*(sample.shape[0]//16)\nsample=sample[0:16*(sample.shape[0]//16),:,:]\nsample=sample.reshape(-1,16,96,96)\nsample.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nx_in=sample\ny_shape=x_in.shape\ny_train=x_in\nx_train=y_train\ntest_ix = 0\ny_test_song = np.copy(y_train[test_ix:test_ix+1])\nx_test_song = np.copy(x_train[test_ix:test_ix+1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys, random, os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport keras\nprint(\"Keras Version: \" + keras.__version__)\nfrom keras.layers import Input, Dense, Activation, Dropout, Flatten, Reshape, Permute, RepeatVector, ActivityRegularization, TimeDistributed, Lambda, SpatialDropout1D\nfrom keras.layers.convolutional import Conv1D, Conv2D, Conv2DTranspose, UpSampling2D, ZeroPadding2D\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.local import LocallyConnected2D\nfrom keras.layers.pooling import MaxPooling2D, AveragePooling2D\nfrom keras.layers.noise import GaussianNoise\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.recurrent import LSTM, SimpleRNN\nfrom keras.initializers import RandomNormal\nfrom keras.losses import binary_crossentropy\nfrom keras.models import Model, Sequential, load_model\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras.utils import plot_model\nfrom keras import backend as K\nfrom keras import regularizers\nfrom keras.engine.topology import Layer\nK.set_image_data_format('channels_first')\nNUM_EPOCHS = 2000\nLR = 0.001\nCONTINUE_TRAIN = False\nPLAY_ONLY = False\nUSE_EMBEDDING = False\nUSE_VAE = False\nWRITE_HISTORY = True\nNUM_RAND_SONGS = 10\nDO_RATE = 0.1\nBN_M = 0.9\nVAE_B1 = 0.02\nVAE_B2 = 0.1\n\nBATCH_SIZE = 350\nMAX_LENGTH = 16\nPARAM_SIZE = 120\nNUM_OFFSETS = 16 if USE_EMBEDDING else 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"y_shape=(1632,16,96,96)\nx_shape=(1632,16,96,96)\nif CONTINUE_TRAIN or PLAY_ONLY:\n\tprint(\"Loading Model...\")\n\tmodel = load_model('model.h5', custom_objects=custom_objects)\nelse:\n\tprint(\"Building Model...\")\n\n\tif USE_EMBEDDING:\n\t\tx_in = Input(shape=x_shape[1:])\n\t\tx = Embedding(x_train.shape[0], PARAM_SIZE, input_length=1)(x_in)\n\t\tx = Flatten(name='pre_encoder')(x)\n\telse:\n\t\tx_in = Input(shape=y_shape[1:])\n\t\tx = Reshape((y_shape[1], -1))(x_in)\n\t\tprint (K.int_shape(x))\n\t\t\n\t\tx = TimeDistributed(Dense(2000, activation='relu'))(x)\n\t\tprint (K.int_shape(x))\n\t\t\n\t\tx = TimeDistributed(Dense(200, activation='relu'))(x)\n\t\tprint (K.int_shape(x))\n\n\t\tx = Flatten()(x)\n\t\tprint (K.int_shape(x))\n\n\t\tx = Dense(1600, activation='relu')(x)\n\t\tprint (K.int_shape(x))\n\t\t\n\t\tif USE_VAE:\n\t\t\tz_mean = Dense(PARAM_SIZE)(x)\n\t\t\tz_log_sigma_sq = Dense(PARAM_SIZE)(x)\n\t\t\tx = Lambda(vae_sampling, output_shape=(PARAM_SIZE,), name='pre_encoder')([z_mean, z_log_sigma_sq])\n\t\telse:\n\t\t\tx = Dense(PARAM_SIZE)(x)\n\t\t\tx = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n\tprint (K.int_shape(x))\n\t\n\tx = Dense(1600, name='encoder')(x)\n\tx = BatchNormalization(momentum=BN_M)(x)\n\tx = Activation('relu')(x)\n\tif DO_RATE > 0:\n\t\tx = Dropout(DO_RATE)(x)\n\tprint (K.int_shape(x))\n\n\tx = Dense(MAX_LENGTH * 200)(x)\n\tprint (K.int_shape(x))\n\tx = Reshape((MAX_LENGTH, 200))(x)\n\tx = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n\tx = Activation('relu')(x)\n\tif DO_RATE > 0:\n\t\tx = Dropout(DO_RATE)(x)\n\tprint (K.int_shape(x))\n\n\tx = TimeDistributed(Dense(2000))(x)\n\tx = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n\tx = Activation('relu')(x)\n\tif DO_RATE > 0:\n\t\tx = Dropout(DO_RATE)(x)\n\tprint (K.int_shape(x))\n\n\tx = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n\tprint (K.int_shape(x))\n\tx = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n\tprint (K.int_shape(x))\n\t\n\tif USE_VAE:\n\t\tmodel = Model(x_in, x)\n\t\tmodel.compile(optimizer=Adam(lr=LR), loss=vae_loss)\n\telse:\n\t\tmodel = Model(x_in, x)\n\t\tmodel.compile(optimizer=RMSprop(lr=LR), loss='binary_crossentropy')\n\n\tplot_model(model, to_file='model.png', show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Compiling SubModels...\")\nfunc = K.function([model.get_layer('encoder').input, K.learning_phase()],\n\t\t\t\t  [model.layers[-1].output])\nenc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)\n\nrand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\nnp.save('rand.npy', rand_vecs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Training...\")\n#save_config()\ntrain_loss = []\nofs = 0\n\nfor iter in range(NUM_EPOCHS):\n\tif USE_EMBEDDING:\n\t\thistory = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n\telse:\n\t\thistory = model.fit(y_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n\n\tloss = history.history[\"loss\"][-1]\n\ttrain_loss.append(loss)\n\tprint(\"Train Loss: \" + str(train_loss[-1]))\n\n\t\n\ti = iter + 1\n\tif i in [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450] or (i % 100 == 0):\n\t\twrite_dir = ''\n\t\tmodel.save('model.h5')\n\t\tprint (\"Saved\")\n\n\t\tif USE_EMBEDDING:\n\t\t\ty_song = model.predict(x_test_song, batch_size=BATCH_SIZE)[0]\n\t\telse:\n            \n\t\t\ty_song = model.predict(y_test_song, batch_size=BATCH_SIZE)[0]\n\t\t\tsong=y_song.reshape(-1,96)\n\t\t\tsong=song.T\n\t\t\ta=np.zeros((128,song.shape[1]))\n\t\t\ta[16:112,:]=song\n\t\t\tmidi.piano_roll_to_midi(a,0,fs=48)\n\n\t\t#util.samples_to_pics(write_dir + 'test', y_song)\n\n\n\t\t#make_rand_songs_normalized(write_dir, rand_vecs)\n            \nprint (\"Done\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"song=y_song.reshape(-1,96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=np.zeros((128,song.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a[16:112,:]=song","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}